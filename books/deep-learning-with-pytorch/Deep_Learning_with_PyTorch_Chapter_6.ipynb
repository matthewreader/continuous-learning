{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning with PyTorch - Chapter 6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPR8ciUHKgBqIZfhlP2mh/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewreader/continuous-learning/blob/main/books/deep-learning-with-pytorch/Deep_Learning_with_PyTorch_Chapter_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could use call the `forward` method of our model, but should not.  There are several hooks that will not be called properly if we use `forward`."
      ],
      "metadata": {
        "id": "OBwxoBgMHao5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-0XttoUK30M",
        "outputId": "98eca049-b872-4bcc-a4fa-597b894764e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.9243],\n",
              "        [-4.2698],\n",
              "        [-4.4230],\n",
              "        [-6.0016],\n",
              "        [-4.2964],\n",
              "        [-3.8035],\n",
              "        [-2.8044],\n",
              "        [-1.9984],\n",
              "        [-3.7702],\n",
              "        [-4.5695],\n",
              "        [-5.1024]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_u = torch.tensor(t_u).unsqueeze(1) # Adds the extra dimension at axis 1\n",
        "t_un = t_u * 0.1\n",
        "\n",
        "# 3 arguements, input size, output size, and bias (True by default)\n",
        "linear_model = nn.Linear(1, 1)\n",
        "linear_model(t_un)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.weight"
      ],
      "metadata": {
        "id": "yyQy4oTFE9B5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf1b82d-adbf-499d-cd13-1e3d9160230f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.6661]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIuQZfpPIJ-B",
        "outputId": "0af83916-fd92-41c1-9696-a306cd102b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.5463], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.nn` expects the zeroth dimension to be the number of batches for a sample.  The output of a model will be B x Nout, where B is the number of batches and Nout is the number of output features.\n",
        "\n",
        "Why batch inputs?\n",
        "\n",
        "1) Maximize computing power.  The full power of our processing unit (GPU, CPU, etc.,) will not be utilized to its fullest if we are passing samples for training one sample at a time."
      ],
      "metadata": {
        "id": "JJIJk75qdwKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_c = torch.tensor(t_c).unsqueeze(1)\n",
        "t_u = torch.tensor(t_u).unsqueeze(1)\n",
        " \n",
        "t_u.shape # B x Nin, where B = 11 and N input features = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76KcMDA2INAc",
        "outputId": "555d7df0-4065-48a5-e8f9-37baee5d9bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 input, 1 output linear model\n",
        "linear_model = nn.Linear(1, 1)\n",
        "optimizer = torch.optim.SGD(\n",
        "    linear_model.parameters(),\n",
        "    lr=1e-2)"
      ],
      "metadata": {
        "id": "Nsa5Sdo0fQjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(linear_model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ9n8u7QfePL",
        "outputId": "12d6e9f4-7fbd-492d-bc4a-e5c298466ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.3601]], requires_grad=True), Parameter containing:\n",
              " tensor([0.7939], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In[13]:\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,\n",
        "                  t_c_train, t_c_val):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        t_p_train = model(t_u_train)\n",
        "        loss_train = loss_fn(t_p_train, t_c_train)\n",
        "\n",
        "        t_p_val = model(t_u_val)\n",
        "        loss_val = loss_fn(t_p_val, t_c_val)\n",
        " \n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        " \n",
        "        if epoch == 1 or epoch % 1000 == 0:\n",
        "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
        "                  f\" Validation loss {loss_val.item():.4f}\")"
      ],
      "metadata": {
        "id": "G2VMOUGff_MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a simple `Sequential` model"
      ],
      "metadata": {
        "id": "7L3kpU5cizel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model = nn.Sequential(\n",
        "            nn.Linear(1, 13),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(13, 1))\n",
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCnaSVY5gqBH",
        "outputId": "c9d3e141-7ae9-4a69-b4d2-6e3a98b61a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=13, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collecting the weights and bias of the linear modules and inspecting their shape:"
      ],
      "metadata": {
        "id": "zGzt3XUckins"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[param.shape for param in seq_model.parameters()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1LyzOJ3j-MO",
        "outputId": "a3215a7f-0547-41e1-ec4e-176d44c512a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([13, 1]), torch.Size([13]), torch.Size([1, 13]), torch.Size([1])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in seq_model.named_parameters():\n",
        "   print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zsugbuykp9M",
        "outputId": "13e07931-7394-4b05-f070-023e2027d3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.weight torch.Size([13, 1])\n",
            "0.bias torch.Size([13])\n",
            "2.weight torch.Size([1, 13])\n",
            "2.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each layer can be named using `OrderedDict`"
      ],
      "metadata": {
        "id": "4UcGjH_Ula9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In[19]:\n",
        "from collections import OrderedDict\n",
        "\n",
        "seq_model = nn.Sequential(OrderedDict([\n",
        "   ('hidden_linear', nn.Linear(1, 8)),\n",
        "   ('hidden_activation', nn.Tanh()),\n",
        "   ('output_linear', nn.Linear(8, 1))\n",
        "]))\n",
        "\n",
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DRRD3bdlLwG",
        "outputId": "f82d39a5-011c-4f12-9194-a20c210e88e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (hidden_linear): Linear(in_features=1, out_features=8, bias=True)\n",
              "  (hidden_activation): Tanh()\n",
              "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We now have more explanatory names for submodules.\n",
        "for name, param in seq_model.named_parameters():\n",
        "   print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvgF0x3wlgeo",
        "outputId": "eac3b1d4-99c6-4076-86cc-7d4e1baa3781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_linear.weight torch.Size([8, 1])\n",
            "hidden_linear.bias torch.Size([8])\n",
            "output_linear.weight torch.Size([1, 8])\n",
            "output_linear.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dgZ49pVblodD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}